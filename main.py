"""
main.py - Main entry point for the Contrato Analyzer tool.
Orchestrates the full workflow: retrieve, identify, analyze, answer.
"""

import sys
import time
from src.reporter import save_companies_with_links  

# Add src to path
sys.path.insert(0, 'src')

from src.scraper import (
    initialize_driver,
    navigate_to_home,
    navigate_to_contracts,
    scroll_and_collect_rows,
    parse_row_data,
    filter_by_company,
    click_company_button,
    click_next_level,
    click_ug_button,
    get_all_document_links,
    close_driver
)
from src.downloader import (
    download_document, 
    should_download
)
from src.parser import (
    extract_text_from_pdf, 
    extract_text_from_url, 
    parse_contract_data
)
from src.analyzer import analyze_contract
from src.reporter import (
    generate_analysis_report,
    print_report,
    save_to_excel,
    create_summary_dataframe
)
from config import CHROME_HEADLESS, FILTER_YEAR

def process_single_company(driver, company_data):
    """
    Process a single company: navigate, extract, analyze.
    Returns a LIST of reports (one per processo found).
    """
    company_id = company_data.get("ID")
    print(f"\n{'='*60}")
    print(f"PROCESSANDO: {company_id} - {company_data.get('Company', 'N/A')}")
    print(f"{'='*60}")
    
    # Step 1: Filter by company
    if not filter_by_company(driver, company_id):
        print("âœ— Falha ao filtrar empresa")
        return []
    
    # Step 2: Click on company
    original_caption = click_company_button(driver, company_id)
    if not original_caption:
        print("âœ— Falha ao clicar na empresa")
        return []
    
    time.sleep(1)
    
    # Step 3: Click next level (Org/Secretaria)
    next_level_caption = click_next_level(driver, original_caption)
    if not next_level_caption:
        print("âš ï¸ Continuando mesmo sem prÃ³ximo nÃ­vel...")
    
    time.sleep(1)
    
    # Step 4: Click UG button (navigates to deepest level)
    ug_caption = click_ug_button(driver)
    if not ug_caption:
        print("âš ï¸ Continuando mesmo sem UG...")
    
    time.sleep(1)
    
    # Step 5: Get ALL document links
    doc_links = get_all_document_links(driver)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Create one report per processo
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    all_reports = []
    
    if not doc_links:
        print("âš ï¸ Nenhum link de documento encontrado")
        report_data = company_data.copy()
        report_data["document_url"] = None
        report_data["document_text"] = None  # â† CORRECT KEY
        
        analysis_results = {
            "flags": [{"type": "no_document", "message": "Documento nÃ£o encontrado", "severity": "medium"}],
            "risk_level": "medium",
            "summary": "NÃ£o foi possÃ­vel acessar o documento do contrato."
        }
        
        report = generate_analysis_report(report_data, analysis_results)
        all_reports.append(report)
    else:
        for i, doc_link in enumerate(doc_links, 1):
            print(f"\n   --- Processando processo {i}/{len(doc_links)} ---")
            
            report_data = company_data.copy()
            report_data["document_url"] = doc_link["href"]
            report_data["document_text"] = doc_link["processo"]  # â† CORRECT KEY
            
            print(f"   ğŸ“ Processo: {doc_link['processo']}")
            print(f"   ğŸ”— URL: {doc_link['href']}")
            
            # Extract and analyze
            if doc_link['href'].lower().endswith('.pdf'):
                filepath = download_document(doc_link['href'])
                if filepath:
                    text_content = extract_text_from_pdf(filepath)
                else:
                    text_content = None
            else:
                text_content = extract_text_from_url(doc_link['href'])
            
            if text_content:
                contract_data = parse_contract_data(text_content)
                analysis_results = analyze_contract(contract_data)
            else:
                analysis_results = {
                    "flags": [{"type": "parse_error", "message": "NÃ£o foi possÃ­vel extrair texto", "severity": "low"}],
                    "risk_level": "low",
                    "summary": "Documento encontrado mas nÃ£o foi possÃ­vel extrair conteÃºdo."
                }
            
            report = generate_analysis_report(report_data, analysis_results)
            all_reports.append(report)
    
    print(f"\nâœ“ {len(all_reports)} relatÃ³rio(s) gerado(s) para esta empresa")
    return all_reports


def main():
    """
    Main function - orchestrates the complete workflow.
    """
    print("\n" + "=" * 60)
    print("     CONTRATO ANALYZER - Iniciando...")
    print("=" * 60 + "\n")
    
    driver = initialize_driver(headless=CHROME_HEADLESS)
    if not driver:
        print("âœ— NÃ£o foi possÃ­vel iniciar o navegador. Encerrando.")
        return
    
    try:
        if not navigate_to_home(driver):
            print("âœ— Falha ao carregar pÃ¡gina inicial. Encerrando.")
            return
        
        if not navigate_to_contracts(driver, year=FILTER_YEAR):
            print("âœ— Falha ao carregar pÃ¡gina de contratos. Encerrando.")
            return

        raw_rows = scroll_and_collect_rows(driver)
        all_companies = parse_row_data(raw_rows)
        
        if not all_companies:
            print("âœ— Nenhuma empresa encontrada. Encerrando.")
            return
        
        print(f"\nâœ“ {len(all_companies)} empresas encontradas!")
        
        all_reports = []
        
        # Process first company as example
        company = all_companies[0]
        print(driver.current_url)
        print(f"\nâ†’ Processando empresa: {company.get('ID')} - {company.get('Company', 'N/A')}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Now returns a LIST of reports
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        reports = process_single_company(driver, company)
        
        if reports:
            all_reports.extend(reports)  # â† extend, not append
            for report in reports:
                print_report(report)
        
        # Save results
        if all_reports:
            summary_df = create_summary_dataframe(all_reports)
            save_to_excel(summary_df, "analysis_summary.xlsx")
        
        # Save companies with links
        companies_processed = [company]
        save_companies_with_links(companies_processed)
        
        print("\nâœ“ Processamento concluÃ­do!")

    except KeyboardInterrupt:
        print("\n\nâš ï¸ Interrompido pelo usuÃ¡rio.")
        
    except Exception as e:
        print(f"\nâœ— Erro inesperado: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        close_driver(driver)

# =============================================================================
# BATCH PROCESSING (for future use)
# =============================================================================
def process_batch(company_list=None, max_companies=None):
    """
    Process multiple companies in batch.
    
    Args:
        company_list: Optional list of company IDs to process
        max_companies: Maximum number of companies to process
    """
    print("\nğŸ”„ Modo batch ainda nÃ£o implementado.")
    print("   Use main() para processar uma empresa por vez.")
    # TODO: Implement batch processing loop


# =============================================================================
# ENTRY POINT
# =============================================================================
if __name__ == "__main__":
    main()